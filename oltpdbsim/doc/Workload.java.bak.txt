package main.java.workload;

import java.io.BufferedReader;
import java.io.BufferedWriter;
import java.io.File;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.InputStreamReader;
import java.io.OutputStreamWriter;
import java.io.Writer;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.Iterator;
import java.util.Map;
import java.util.Set;
import java.util.TreeMap;
import java.util.Map.Entry;
import main.java.db.Tuple;
import main.java.db.Database;
import main.java.db.Table;
import main.java.entry.Global;
import org.apache.commons.configuration.AbstractFileConfiguration;
import org.apache.commons.configuration.ConfigurationException;
import org.apache.commons.configuration.PropertiesConfiguration;
import org.apache.commons.math3.distribution.ZipfDistribution;

public class Workload implements java.io.Serializable {	

	private static final long serialVersionUID = 1L;
	
	public boolean warmingup;
	
	public int tbl = 0;		
	public Map<Integer, Integer> tbl_types = null;
	public Map<Integer, ArrayList<Integer>> schema = null;
	
	Map<Integer, Double> tr_proportions = null;
	Map<Integer, ArrayList<Integer>> tr_tuple_distributions = null;	
	Map<Integer, ArrayList<Integer>> tr_changes = null;
	String file_name = null;
	
	public int tr_types = 0;
	private Map<Integer, ArrayList<Transaction>> wrl_transactions;
	
	// new
	public int[] trTypes = null;
	public double[] trProbabilities = null;
	
	// Cache
	protected HashMap<Integer, ArrayList<Integer>> _cache;
	protected ArrayList<Integer> _cache_keys;
	protected int _cache_id;		
	
	Workload(String file) {
		file_name = file;
		BufferedReader config_file = null; 
	    AbstractFileConfiguration parameters = null;
	    
	    try {
	    	config_file = new BufferedReader(
	    			new InputStreamReader(getClass().getResourceAsStream(file_name)));
	    	
			Global.LOGGER.info("Configuration file "+file_name+" is found under src/main/resources and read.");
	    	
		    //Load configuration parameters
	    	parameters = new PropertiesConfiguration();
			parameters.load(config_file);
						
			//Read the number of tables and types of transactions
			tbl = parameters.getInt("tables");
			tr_types = parameters.getInt("transaction.types");
			
			Global.LOGGER.info("Number of database tables: "+tbl);
			Global.LOGGER.info("Types of workload transactions: "+tr_types);
			
		} catch (ConfigurationException e) {
			e.printStackTrace();
		} finally {
			if(config_file != null) {
				try {
					config_file.close();			
				} catch (IOException e) {
					e.printStackTrace();
				}			
			}
		}
	    
	    //Initialize other variables
	    this.warmingup = false;
	    this.tbl_types = new HashMap<Integer, Integer>();
	    this.schema = new HashMap<Integer, ArrayList<Integer>>();
	    this.tr_proportions = new HashMap<Integer, Double>();
	    this.tr_tuple_distributions = new HashMap<Integer, ArrayList<Integer>>();	    
	    this.tr_changes = new HashMap<Integer, ArrayList<Integer>>();	    
	    this._cache = new HashMap<Integer, ArrayList<Integer>>();
		this._cache_keys = new ArrayList<Integer>();
		this._cache_id = 0;
		this.wrl_transactions = new TreeMap<Integer, ArrayList<Transaction>>();
	}
	
	// Generate data set and create a new Transaction
	public Set<Integer> getTrTupleSet(Database db, int type) {		
		return this.getTrTupleSet(db, type);		
	}
	
	public void warmup(Database db) {
		Global.LOGGER.info("-----------------------------------------------------------------------------");
		Global.LOGGER.info("Warming up the database ...");
		Global.LOGGER.info("Targeting "+1000+" transaction generation ...");		

		this.warmingup = true;
		
		// i -- Transaction types
		for(int i = 1; i <= this.tr_types; i++) {
			// Calculate the number of transactions to be created for a specific type
			int tr_nums = (int) Math.ceil(this.tr_proportions.get(i) * 1000);			
			Global.LOGGER.info("Generating "+tr_nums+" transactions of type "+i+" ...");

			// j -- number of Transactions for a specific Transaction type
			for(int j = 1; j <= tr_nums; j++) {				
				this.getTrTupleSet(db, i);
			}			
		}
		
		this.warmingup = false;
	}
	
	// Generates required number of Transactions for a specific Workload with a specific Database
	public void generateWorkload(Database db) {	
		
		Global.LOGGER.info("-----------------------------------------------------------------------------");
		Global.LOGGER.info("Starting workload generation for run "+Global.repeated_runs+" ...");
		
		ArrayList<Transaction> trList;
		Transaction tr;
		int tr_nums = 0;
		
		// Workload file generation
		File trFile = null;
		Writer writer = null;
		
//		// Re-seed the Random Data Generator
//		Global.rand.setSeed(Global.repeated_runs);
//		Global.rdg.reSeed(Global.repeated_runs);
		
		// Assign Data popularity for Primary tables only
//		this.generateDataPopularity(db); 
		
		Global.LOGGER.info("-----------------------------------------------------------------------------");
		//Global.LOGGER.info("Targeting "+Global.transactions+" transaction generation ...");
		
		// i -- Transaction types
		for(int i = 1; i <= this.tr_types; i++) {
			
			// Create individual file for different transaction types
			trFile = new File(Global.wrl_dir+"run"+Global.repeated_runs+"/"+"t"+i+".tr");
			
			try {
				
				trFile.getParentFile().mkdirs();
				trFile.createNewFile();				
				
				try {
					writer = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(trFile), "utf-8"));
					
					// Calculate the number of transactions to be created for a specific type
					tr_nums = (int) Math.ceil(this.tr_proportions.get(i) * Global.transactions);			
					trList = new ArrayList<Transaction>();
					
					Global.LOGGER.info("Generating "+tr_nums+" transactions of type "+i+" ...");

					// j -- number of Transactions for a specific Transaction type
					for(int j = 1; j <= tr_nums; j++) {				
//						// Generate data set and create a new Transaction
//						++Global.global_trSeq;
//						
//						trDataSet = this.getTrTupleSet(db, i);
//						tr = new Transaction(Global.global_trSeq, trDataSet);
//						tr.setTr_type(i);
						
						tr = this.getOneTransaction(db, i);
						
						//System.out.println("@ T"+tr.getTr_dataSet());
						// Write Transaction details into file
						//writer.write(tr.getTr_id()+" ");
						
						// Write line numbers
						//++tr_count;
						//writer.write(tr_count+" ");
						
						Iterator<Integer> data =  tr.getTr_dataSet().iterator();
						while(data.hasNext()) {
							writer.write(Integer.toString(data.next()));							
							
							if(data.hasNext())
								writer.write(" "); 
						} // end -- while() loop
						
						writer.write("\n");
						
						trList.add(tr);						
					} // end--j
										
					//System.out.println("--> size = "+db.slidingWindowDataCount.size());
					//System.out.println(db.slidingWindowDataCount);
					
					Global.LOGGER.info("Total "+trList.size()+" transactions of type "+i+" have generated.");
					this.wrl_transactions.put(i, trList);
					
				} catch (Exception e) {
					e.printStackTrace();
				} finally {
					writer.close();
				}				
			} catch (IOException e) {
				e.printStackTrace();
			}			
		} // end--i	
		
		// Update statistic
		db.updateTupleCounts();
		
		Global.LOGGER.info("Total "+Global.global_trSeq+" Transactions have generated.");		
	}
	
	private Transaction getOneTransaction(Database db, int i) {
		++Global.global_trSeq;
		return (new Transaction(Global.global_trSeq, i, this.getTrTupleSet(db, i)));
	}
	
	//Generates Zipf Ranks for the Primary Tables
	public void generateDataPopularity(Database db) {
		
		Global.LOGGER.info("-----------------------------------------------------------------------------");
		Global.LOGGER.info("Generating data popularity profiles for primary tables ...");
		
		double exponent = 2.0; // 2~3
		
		for(Entry<Integer, Table> tbl_entry : db.getDb_tables().entrySet()) {
			
			Table tbl = tbl_entry.getValue();
			
	    	if(tbl.getTbl_type() == 0)
	    		this.getZipfProbability(tbl, exponent);	    	
		}
		
		Global.LOGGER.info("Data popularity profile generation has been completed.");
	}
	
	// Calculate Zipf probability P(X = x) for all the Data tuples in a Table following Zipf Distribution	
	private void getZipfProbability(Table tbl, double exponent) {		
		ZipfDistribution zipf = new ZipfDistribution(tbl.getTbl_init_tuples(), exponent);
		zipf.reseedRandomGenerator(Global.repeated_runs);
		
		int d = 1;	
		for(Entry<Integer, Tuple> data : tbl.getTbl_tuples().entrySet()) {
			tbl.getTbl_dataRank()[(d % tbl.getTbl_tuples().size())+1] 
					= data.getValue().getTuple_pk();
			
			d++;
		}			
	}	
}